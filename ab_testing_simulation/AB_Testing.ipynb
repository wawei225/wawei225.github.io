{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d7b07d-7011-459c-9f62-2aa2dc353e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664dacc2-368e-44e9-a0e4-18451cd8f2b9",
   "metadata": {},
   "source": [
    "1. Data Cleaning ( I will use SQL which is a commonly used tool when extracting and cleaning data)\n",
    "3. Evaluate SRM and general metrics\n",
    "4. Evaluate A/B testing Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46286d98-3e0b-44fb-8b67-d538f8efce4e",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8107804c-744a-400f-a119-21013cca1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files into Pandas\n",
    "experiment_df = pd.read_csv('experiment_data/experiment_table.csv')\n",
    "user_df = pd.read_csv('experiment_data/user_table.csv')\n",
    "event_df = pd.read_csv('experiment_data/event_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd1dce-b156-455f-bcb8-ea80476b7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract TA users, for SRM check, we look at the first 3 days of data to determine if the experiment data is splitted randomlly. \n",
    "# In addition, we check for general metrics between A and AA group to see if there are random. The general metric should have no significant difference between these two groups.\n",
    "# The general metrics we evaluate will be the user-level click through rate for the discovery section on the home page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "076ef749-bab2-43ea-b58e-eb41a0f86202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  group_id  event_date device\n",
      "0        1         1  2024-10-10    ios\n",
      "1        2         0  2024-10-14    ios\n",
      "2        3         1  2024-10-23    ios\n",
      "3        4         2  2024-10-27    ios\n",
      "4        5         0  2024-10-20    ios\n"
     ]
    }
   ],
   "source": [
    "print(experiment_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e5a8ca4-0c5d-42b3-be6d-4aa694e6a1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ios' 'web' 'android']\n"
     ]
    }
   ],
   "source": [
    "print(experiment_df['device'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34d8f23d-9732-48a6-94ee-deb26d1d21d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id device            timestamp    event_name page_name section_name  \\\n",
      "0        1    ios  2024-10-10 16:56:00     view_page      home         None   \n",
      "1        1    ios  2024-10-10 16:56:01  view_section      home    discovery   \n",
      "2        1    ios  2024-10-10 16:57:32  view_section      home     trending   \n",
      "3        2    ios  2024-10-14 15:29:00     view_page      home         None   \n",
      "4        2    ios  2024-10-14 15:29:01  view_section      home    discovery   \n",
      "\n",
      "   group_id  event_date  \n",
      "0         1  2024-10-10  \n",
      "1         1  2024-10-10  \n",
      "2         1  2024-10-10  \n",
      "3         0  2024-10-14  \n",
      "4         0  2024-10-14  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create SQLite in-memory database\n",
    "conn = sqlite3.connect(\":memory:\")  # Uses in-memory storage (free and fast)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 3: Store DataFrames as SQL tables\n",
    "experiment_df.to_sql(\"experiment\", conn, index=False, if_exists=\"replace\")\n",
    "user_df.to_sql(\"user\", conn, index=False, if_exists=\"replace\")\n",
    "event_df.to_sql(\"event\", conn, index=False, if_exists=\"replace\")\n",
    "\n",
    "# Step 4: Run SQL queries for data cleaning (example: removing duplicates)\n",
    "TA_df = pd.read_sql_query(\"\"\"\n",
    "\n",
    "with TA as (\n",
    "    select \n",
    "        distinct e.user_id\n",
    "    from event e \n",
    "    left join experiment exp\n",
    "            on e.user_id = exp.user_id \n",
    "            and date(e.timestamp) >= exp.event_date\n",
    "            and e.device = exp.device \n",
    "    where \n",
    "        event_name = 'view_section'\n",
    "        and page_name = 'home'\n",
    "        and section_name = 'trending'\n",
    "        and exp.device = 'ios'\n",
    ")\n",
    "\n",
    "select \n",
    "    e.*,\n",
    "    exp.group_id,\n",
    "    exp.event_date\n",
    "from event e \n",
    "left join experiment exp\n",
    "    on e.user_id = exp.user_id \n",
    "    and date(e.timestamp) >= exp.event_date\n",
    "    and e.device = exp.device     \n",
    "where e.user_id in (select * from TA)\n",
    "\n",
    "\"\"\", conn)\n",
    "\n",
    "# Step 5: Retrieve and process cleaned data\n",
    "print(TA_df.head())\n",
    "\n",
    "# Close connection when done\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61dea4d3-9341-42b5-9757-aa3849d0ce8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Observed Counts': {'AA': 3655, 'A': 3538, 'B': 3507}, 'Expected Counts': {'AA': 3566.6630999999998, 'A': 3566.6630999999998, 'B': 3566.6738}, 'Chi-Square Statistic': 3.416620125067091, 'p-value': 0.18117170290829315, 'SRM Detected': False}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def check_srm(n_AA, n_A, n_B, ratio_AA, ratio_A, ratio_B):\n",
    "    \"\"\"\n",
    "    Check for Sample Ratio Mismatch (SRM) using a chi-square test.\n",
    "\n",
    "    Parameters:\n",
    "    - n_AA: Observed user count in AA group\n",
    "    - n_A: Observed user count in A group\n",
    "    - n_B: Observed user count in B group\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing chi-square statistic, p-value, expected counts, and SRM status\n",
    "    \"\"\"\n",
    "    # Total users\n",
    "    N = n_AA + n_A + n_B\n",
    "\n",
    "    # Expected count assuming equal distribution\n",
    "    expected = [N * ratio_AA, N * ratio_A, N * ratio_B]\n",
    "    observed = [n_AA, n_A, n_B]\n",
    "\n",
    "    # Perform chi-square test\n",
    "    chi2_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "    # Determine if there is a significant SRM\n",
    "    srm_detected = p_value < 0.05\n",
    "\n",
    "    return {\n",
    "        'Observed Counts': {'AA': n_AA, 'A': n_A, 'B': n_B},\n",
    "        'Expected Counts': {'AA': expected[0], 'A': expected[1], 'B': expected[2]},\n",
    "        'Chi-Square Statistic': chi2_stat,\n",
    "        'p-value': p_value,\n",
    "        'SRM Detected': srm_detected\n",
    "    }\n",
    "\n",
    "# Example Usage:\n",
    "result = check_srm(n_AA=TA_df[(TA_df['event_date']<='2024-10-07')& (TA_df['group_id']==0)]['user_id'].nunique(), \n",
    "                   n_A=TA_df[(TA_df['event_date']<='2024-10-07')& (TA_df['group_id']==1)]['user_id'].nunique(), \n",
    "                   n_B=TA_df[(TA_df['event_date']<='2024-10-07')& (TA_df['group_id']==2)]['user_id'].nunique(), \n",
    "                   ratio_AA=0.333333, ratio_A=0.333333, ratio_B=0.333334)  # Replace with real numbers\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6981f7-2701-4d9d-a23d-72e3231b927a",
   "metadata": {},
   "source": [
    "**Check for general metrics between A and AA group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a835204-4887-46b7-8da4-591396b506a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id device            timestamp    event_name page_name section_name  \\\n",
      "0        1    ios  2024-10-10 16:56:00     view_page      home         None   \n",
      "1        1    ios  2024-10-10 16:56:01  view_section      home    discovery   \n",
      "2        1    ios  2024-10-10 16:57:32  view_section      home     trending   \n",
      "3        2    ios  2024-10-14 15:29:00     view_page      home         None   \n",
      "4        2    ios  2024-10-14 15:29:01  view_section      home    discovery   \n",
      "\n",
      "   group_id device  event_date  \n",
      "0         1    ios  2024-10-10  \n",
      "1         1    ios  2024-10-10  \n",
      "2         1    ios  2024-10-10  \n",
      "3         0    ios  2024-10-14  \n",
      "4         0    ios  2024-10-14  \n"
     ]
    }
   ],
   "source": [
    "print(TA_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "edec23c8-7e4a-47b0-a2a0-19ce8e563edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group_id  num_user_click  num_user_exposed\n",
      "0         0               0             29966\n",
      "1         1               0             29952\n",
      "2         2               0             29911\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create SQLite in-memory database\n",
    "conn = sqlite3.connect(\":memory:\")  # Uses in-memory storage (free and fast)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 3: Store DataFrames as SQL tables\n",
    "TA_df.to_sql(\"ta_df\", conn, index=False, if_exists=\"replace\")\n",
    "\n",
    "# Step 4: Run SQL queries for data cleaning (example: removing duplicates)\n",
    "general_metric = pd.read_sql_query(\"\"\"\n",
    "\n",
    "    select \n",
    "        group_id,\n",
    "        count(distinct \n",
    "            case when event_name = 'click_item' and page_name ='home' and section_name ='discovery'\n",
    "                then user_id\n",
    "            else null end) as num_user_click,\n",
    "        count(distinct \n",
    "            case when event_name = 'view_section' and page_name ='home' and section_name ='discovery'\n",
    "                then user_id\n",
    "            else null end) as num_user_exposed\n",
    "    from ta_df \n",
    "    group by 1\n",
    "\n",
    "\"\"\", conn)\n",
    "\n",
    "# Step 5: Retrieve and process cleaned data\n",
    "print(general_metric.head())\n",
    "\n",
    "# Close connection when done\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09923f18-0870-4538-a28b-42ffa9b3e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trending']\n"
     ]
    }
   ],
   "source": [
    "print(event_df[event_df['event_name']=='click_item']['section_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1c12e-d12c-4d0f-8ae8-4413c58f28d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fee0f10a-709c-4475-8973-d07bdc3c3b34",
   "metadata": {},
   "source": [
    "Including a part for calculating the MDE, conversion rate, and sample size from historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9300a-8f02-4edb-9b80-eb8b2fbd2eb4",
   "metadata": {},
   "source": [
    "Evaluating historical data for baseline conversation rate.\n",
    "* Time Series trend\n",
    "* Average Conversation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b8522-0adc-434c-b1d4-038e6864ac7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0522b995-d961-47aa-a25e-8c79133eddb2",
   "metadata": {},
   "source": [
    "# Break\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b254e17-c118-4030-8835-b634e3864626",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccd9cf7b-60d9-49da-b266-0445bce6e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_df = event_hist_df[\n",
    "    (event_hist_df['device'] == 'ios') & \n",
    "    (event_hist_df['event_name'] == 'view_section') & \n",
    "    (event_hist_df['section_name'] == 'trending')\n",
    "]\n",
    "\n",
    "convert_df = event_hist_df[\n",
    "    (event_hist_df['device'] == 'ios') & \n",
    "    (event_hist_df['event_name'] == 'click_item') & \n",
    "    (event_hist_df['section_name'] == 'trending')\n",
    "]\n",
    "\n",
    "conversion_rate = convert_df['user_id'].nunique()/ta_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "183c93bd-7e06-4b58-9bd3-1d16da30c527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-01 00:00:00\n",
      "2024-10-01 00:03:18\n"
     ]
    }
   ],
   "source": [
    "print(event_hist_df['timestamp'].min())\n",
    "print(event_hist_df['timestamp'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e40c98d-2843-4e20-979e-8440eab802a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bef32f37-4605-422f-aa30-772458c9609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595009981859452\n"
     ]
    }
   ],
   "source": [
    "print(conversion_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f56cc-d787-4e73-986f-196b908df53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2e293-9a66-4d94-b9f0-5f5ebc7d5e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4ee03354-88cb-4dbf-a709-2810846c2cb7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad8ea524-1589-459d-a365-70d598ac2b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175237"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load CSV files into Pandas\n",
    "experiment_df = pd.read_csv('data/experiment_table.csv')\n",
    "user_df = pd.read_csv('data/user_table.csv')\n",
    "event_df = pd.read_csv('data/event_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdd7d551-13bb-4e98-b127-29ed7034fa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   device registration_date geo      lang\n",
      "0        1  android        2024-01-08  JP  Japanese\n",
      "1        2  android        2024-01-09  JP  Japanese\n",
      "2        3      web        2024-01-05  JP  Japanese\n",
      "3        4      web        2024-01-14  US  Japanese\n",
      "4        5      ios        2024-01-07  JP  Japanese\n"
     ]
    }
   ],
   "source": [
    "print(user_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e07844-1c1e-44f5-a1ce-e1ff2aaa5212",
   "metadata": {},
   "source": [
    "Success Metrics\n",
    "* percentage of users who click the item in trending section on the home page among all the users who saw the trending section : click through rate over the experiment period -> considering diminishing return\n",
    "\n",
    "Data Cleaning\n",
    "* experiment table should only contains  user_id where the device = ios\n",
    "* there should not be duplicate user_id in experiment table (no user is assigned to two different groups)\n",
    "* the event table for each user should happen \"after\" the event_date in the experiment table ( the event should only be accountable after they are assigned into an experiment group )\n",
    "* only users who have the event view_section = trending should be considered ( the users who actually see the UI changes )\n",
    "* registration date should be earlier than experiment and event date\n",
    "\n",
    "group_id | num_user_click | num_user_exposed\n",
    "\n",
    "1. merge experiment group\n",
    "2. remove non-ios user\n",
    "3. remove user who never exposed to the trending section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a7ee0f2-0279-45ba-a3e9-a059217e08d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id   device            timestamp    event_name page_name section_name\n",
      "0         1  android  2024-01-08 14:18:00     view_page      home          NaN\n",
      "1         1  android  2024-01-08 14:18:01  view_section      home    discovery\n",
      "2         1  android  2024-01-08 14:22:43  view_section      home     trending\n",
      "3         1  android  2024-01-08 14:24:16    click_item      home     trending\n",
      "4         1  android  2024-01-08 14:24:52     view_page      home          NaN\n",
      "5         1  android  2024-01-08 14:24:53  view_section      home    discovery\n",
      "6         1  android  2024-01-08 14:28:43    click_item      home    discovery\n",
      "7         1  android  2024-01-08 14:29:16  view_section      home     trending\n",
      "8         1  android  2024-01-08 14:30:28     view_page      home          NaN\n",
      "9         1  android  2024-01-08 14:30:29  view_section      home    discovery\n",
      "10        1  android  2024-01-08 14:33:11    click_item      home    discovery\n",
      "11        1  android  2024-01-08 14:34:11  view_section      home     trending\n",
      "12        1  android  2024-01-08 14:36:39     view_page      home          NaN\n",
      "13        1  android  2024-01-08 14:36:40  view_section      home    discovery\n",
      "14        1  android  2024-01-08 14:37:50    click_item      home    discovery\n",
      "15        1  android  2024-01-08 14:42:02  view_section      home     trending\n",
      "16        1  android  2024-01-08 14:43:22     view_page      item          NaN\n",
      "17        1  android  2024-01-08 14:43:23  view_section      item  description\n",
      "18        1  android  2024-01-08 14:45:23  view_section      item       review\n",
      "19        1  android  2024-01-08 14:46:01     view_page      item          NaN\n"
     ]
    }
   ],
   "source": [
    "print(event_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5b30c-f053-43c4-8148-ad079c3d5584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f7583e2-ec98-452a-8368-b94a03581310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group_id  num_user_click  num_user_exposed\n",
      "0         0              24                24\n",
      "1         1              39                39\n",
      "2         2              37                37\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create SQLite in-memory database\n",
    "conn = sqlite3.connect(\":memory:\")  # Uses in-memory storage (free and fast)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 3: Store DataFrames as SQL tables\n",
    "experiment_df.to_sql(\"experiment\", conn, index=False, if_exists=\"replace\")\n",
    "user_df.to_sql(\"user\", conn, index=False, if_exists=\"replace\")\n",
    "event_df.to_sql(\"event\", conn, index=False, if_exists=\"replace\")\n",
    "\n",
    "# Step 4: Run SQL queries for data cleaning (example: removing duplicates)\n",
    "check_df = pd.read_sql_query(\"\"\"\n",
    "    select \n",
    "        group_id,\n",
    "        count(distinct \n",
    "            case when event_name = 'click_item' and page_name ='home' and section_name ='trending'\n",
    "                then e.user_id\n",
    "            else null end) as num_user_click,\n",
    "        count(distinct \n",
    "            case when event_name = 'view_section' and page_name ='home' and section_name ='trending'\n",
    "                then e.user_id\n",
    "            else null end) as num_user_exposed\n",
    "    from event e \n",
    "    left join experiment exp \n",
    "        on e.user_id = exp.user_id \n",
    "        and date(e.timestamp) >= exp.event_date\n",
    "        and e.device = exp.device \n",
    "    where group_id is not null \n",
    "    group by 1\n",
    "\"\"\", conn)\n",
    "\n",
    "# Step 5: Retrieve and process cleaned data\n",
    "print(check_df.head())\n",
    "\n",
    "# Close connection when done\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cf7d3d1-61fc-4461-a318-ccf7aeeeb580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [user_id, device, timestamp, event_name, page_name, section_name, user_id, group_id, event_date, device]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(check_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae65916f-beed-47cc-aa86-a49be477e9b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (897135227.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    df = pd.read_csv('C:\\Users\\hwhua\\Desktop\\AB_Testing_Mock\\data\\event_table.csv')\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/hwhuaDesktop\\AB_Testing_Mock\\data\\event_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d559b36-1733-43f1-9970-46bb53aab51c",
   "metadata": {},
   "source": [
    "# check for SRM \n",
    "\n",
    "experiment ratio\n",
    "actual ratio \n",
    "\n",
    "Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d47fabc4-12e1-4cd4-bd46-f06b62cdd590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Observed Counts': {'AA': 3400, 'A': 3300, 'B': 3300}, 'Expected Counts': {'AA': 3333.33, 'A': 3333.33, 'B': 3333.34}, 'Chi-Square Statistic': 2.0002010198029847, 'p-value': 0.3678424675031903, 'SRM Detected': False}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def check_srm(n_AA, n_A, n_B, ratio_AA, ratio_A, ratio_B):\n",
    "    \"\"\"\n",
    "    Check for Sample Ratio Mismatch (SRM) using a chi-square test.\n",
    "\n",
    "    Parameters:\n",
    "    - n_AA: Observed user count in AA group\n",
    "    - n_A: Observed user count in A group\n",
    "    - n_B: Observed user count in B group\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing chi-square statistic, p-value, expected counts, and SRM status\n",
    "    \"\"\"\n",
    "    # Total users\n",
    "    N = n_AA + n_A + n_B\n",
    "\n",
    "    # Expected count assuming equal distribution\n",
    "    expected = [N * ratio_AA, N * ratio_A, N * ratio_B]\n",
    "    observed = [n_AA, n_A, n_B]\n",
    "\n",
    "    # Perform chi-square test\n",
    "    chi2_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "    # Determine if there is a significant SRM\n",
    "    srm_detected = p_value < 0.05\n",
    "\n",
    "    return {\n",
    "        'Observed Counts': {'AA': n_AA, 'A': n_A, 'B': n_B},\n",
    "        'Expected Counts': {'AA': expected[0], 'A': expected[1], 'B': expected[2]},\n",
    "        'Chi-Square Statistic': chi2_stat,\n",
    "        'p-value': p_value,\n",
    "        'SRM Detected': srm_detected\n",
    "    }\n",
    "\n",
    "# Example Usage:\n",
    "result = check_srm(n_AA=3400, n_A=3300, n_B=3300, ratio_AA=0.333333, ratio_A=0.333333, ratio_B=0.333334)  # Replace with real numbers\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed7fceb2-c936-411f-b9bb-e13ba53d74fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CTR_A': 0.42, 'CTR_B': 0.74, 'CTR_Difference': 0.32, 'Z-score': 3.919183588453085, 'p-value': 8.884941911446731e-05, '95% CI': (0.15996961078815633, 0.4800303892118437), 'Significant?': True}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def z_test_proportions(x_A, n_A, x_B, n_B, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform a two-proportion z-test for comparing conversion rates (CTR) between two groups.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_A: Number of converted users in Control\n",
    "    - n_A: Total users in Control\n",
    "    - x_B: Number of converted users in Test\n",
    "    - n_B: Total users in Test\n",
    "    - alpha: Significance level (default = 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing Z-score, p-value, confidence interval, and test result\n",
    "    \"\"\"\n",
    "    # Compute proportions\n",
    "    p_A = x_A / n_A\n",
    "    p_B = x_B / n_B\n",
    "\n",
    "    # Compute pooled proportion\n",
    "    p_pool = (x_A + x_B) / (n_A + n_B)\n",
    "\n",
    "    # Compute standard error\n",
    "    SE = np.sqrt(p_pool * (1 - p_pool) * (1/n_A + 1/n_B))\n",
    "\n",
    "    # Compute z-score\n",
    "    Z = (p_B - p_A) / SE\n",
    "\n",
    "    # Compute two-tailed p-value\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(Z)))\n",
    "\n",
    "    # Confidence interval (95%)\n",
    "    z_critical = stats.norm.ppf(1 - alpha/2)  # 1.96 for 95% CI\n",
    "    margin_of_error = z_critical * SE\n",
    "    confidence_interval = ((p_B - p_A) - margin_of_error, (p_B - p_A) + margin_of_error)\n",
    "\n",
    "    # Determine significance\n",
    "    is_significant = p_value < alpha\n",
    "\n",
    "    return {\n",
    "        'CTR_A': p_A,\n",
    "        'CTR_B': p_B,\n",
    "        'CTR_Difference': p_B - p_A,\n",
    "        'Z-score': Z,\n",
    "        'p-value': p_value,\n",
    "        '95% CI': confidence_interval,\n",
    "        'Significant?': is_significant\n",
    "    }\n",
    "\n",
    "# Example Usage:\n",
    "x_A, n_A = 63, 150  # Control group (300 clicks, 5000 users)\n",
    "x_B, n_B = 37, 50  # Test group (350 clicks, 5000 users)\n",
    "\n",
    "result = z_test_proportions(x_A, n_A, x_B, n_B)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9cb5c0d2-6212-4900-a58f-ff89e8a244ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "print(37/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2cf04-6271-4924-8ff2-4cbacc0d26d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c05f5-2ac2-4c5e-93c8-aa54b8a00182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8217a-7684-46bc-b70f-fcf67b0e27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id  num_user_click  num_user_exposed\n",
    "0         0              24                24\n",
    "1         1              39                39\n",
    "2         2              37                37\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
